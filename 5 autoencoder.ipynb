{
 "metadata": {
  "name": "",
  "signature": "sha256:25a5b478a9d8c078f0fa526352b431168f0ca5998d6e0c1446cd6b7aea49c10a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "from __future__ import division\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import theano\n",
      "\n",
      "import data\n",
      "import lasangeutils\n",
      "import utils\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.gridspec\n",
      "import seaborn as sns\n",
      "%matplotlib inline\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.manifold import TSNE \n",
      "\n",
      "from lasagne import layers\n",
      "from lasagne.updates import nesterov_momentum, rmsprop, adadelta\n",
      "from lasagne.nonlinearities import softmax\n",
      "from nolearn.lasagne import NeuralNet\n",
      "from nolearn.lasagne import negative_log_likelihood"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GTX 670\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reload(data)\n",
      "# reload(lasangeutils)\n",
      "# reload(utils)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hw = 48\n",
      "%time X_orig, y_orig = data.load_data(resize_shape=(hw, hw), scale=True)\n",
      "\n",
      "enc = LabelEncoder()\n",
      "X = X_orig.astype(np.float32)\n",
      "\n",
      "# Normalize images\n",
      "X -= np.mean(X, axis = 0)\n",
      "X /= np.std(X, axis = 0)\n",
      "\n",
      "y = enc.fit_transform(y_orig).astype(np.int32)\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X.reshape(-1, hw * hw), y, test_size=0.05, random_state=42)\n",
      "X_train, X_test = X_train.reshape(-1, 1, hw, hw), X_test.reshape(-1, 1, hw, hw) # because train_test_split requires array to X\n",
      "\n",
      "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished reading directories; found 30336 images\n",
        "Scaling image output\n",
        "Resizing all images to (48, 48)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 17.9 s, sys: 1.52 s, total: 19.4 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 31.9 s\n",
        "(28819, 1, 48, 48)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (28819,) (1517, 1, 48, 48) (1517,)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = NeuralNet(\n",
      "    eval_size=0.1,\n",
      "\n",
      "    layers=[\n",
      "        ('input', layers.InputLayer),\n",
      "\n",
      "        ('conv1', layers.Conv2DCCLayer),\n",
      "        ('pool1', layers.MaxPool2DCCLayer),\n",
      "        ('dropout1', layers.DropoutLayer),\n",
      "\n",
      "        ('conv2', layers.Conv2DCCLayer),\n",
      "        ('pool2', layers.MaxPool2DCCLayer),\n",
      "        ('dropout2', layers.DropoutLayer),\n",
      "\n",
      "        ('conv3', layers.Conv2DCCLayer),\n",
      "        ('pool3', layers.MaxPool2DCCLayer),\n",
      "        ('dropout3', layers.DropoutLayer),\n",
      "\n",
      "#         ('conv4', layers.Conv2DCCLayer),\n",
      "#         ('pool4', layers.MaxPool2DCCLayer),\n",
      "\n",
      "        ('hidden5', layers.DenseLayer),\n",
      "#         ('maxpool5', layers.FeaturePoolLayer),\n",
      "        ('dropout5', layers.DropoutLayer),\n",
      "\n",
      "        ('hidden6', layers.DenseLayer),\n",
      "#         ('maxpool6', layers.FeaturePoolLayer),\n",
      "        ('dropout6', layers.DropoutLayer),\n",
      "\n",
      "        ('hidden7', layers.DenseLayer),\n",
      "        ('dropout7', layers.DropoutLayer),\n",
      "\n",
      "        ('output', layers.DenseLayer),\n",
      "    ],\n",
      "\n",
      "    input_shape=(None, 1, hw, hw),\n",
      "\n",
      "    conv1_num_filters=64, conv1_filter_size=(5, 5),\n",
      "#     conv1_strides=(4, 4), conv1_pad=2,\n",
      "    pool1_ds=(2, 2),\n",
      "#     pool1_strides=(2, 2),\n",
      "    dropout1_p=0.2,\n",
      "\n",
      "    conv2_num_filters=128, conv2_filter_size=(5, 5),\n",
      "#     conv2_pad=2,\n",
      "    pool2_ds=(2, 2),\n",
      "    dropout2_p=0.2,\n",
      "\n",
      "    conv3_num_filters=256, conv3_filter_size=(5, 5),\n",
      "#     conv3_pad=1,\n",
      "    pool3_ds=(2, 2),\n",
      "#     pool3_strides=(2, 2),\n",
      "    dropout3_p=0.2,\n",
      "\n",
      "#     conv4_num_filters=128, conv4_filter_size=(3, 3),\n",
      "#     pool4_ds=(2, 2),\n",
      "#     dropout4_p=0.5,\n",
      "\n",
      "    hidden5_num_units=2048,\n",
      "#     maxpool5_ds=2,\n",
      "    dropout5_p=0.5,\n",
      "\n",
      "    hidden6_num_units=2048,\n",
      "#     maxpool6_ds=2,\n",
      "    dropout6_p=0.5,\n",
      "\n",
      "    hidden7_num_units=2048,\n",
      "    dropout7_p=0.5,\n",
      "\n",
      "    output_num_units=len(set(y_train)),\n",
      "\n",
      "#     loss=negative_log_likelihood,\n",
      "\n",
      "    batch_iterator_train=lasangeutils.MyBatchIterator(batch_size=128),\n",
      "    batch_iterator_test=lasangeutils.MyBatchIterator(batch_size=128),\n",
      "\n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=theano.shared(lasangeutils.float32(0.005)),\n",
      "    update_momentum=theano.shared(lasangeutils.float32(0.9)),\n",
      "\n",
      "#     update=rmsprop,\n",
      "#     update=adadelta,\n",
      "\n",
      "    regression=False,\n",
      "    output_nonlinearity=softmax,\n",
      "\n",
      "    on_epoch_finished=[\n",
      "        lasangeutils.AdjustVariable('update_learning_rate', start=0.005, stop=0.001),\n",
      "        lasangeutils.AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
      "        lasangeutils.EarlyStopping(patience=10)\n",
      "    ],\n",
      "\n",
      "    max_epochs=1000,\n",
      "    verbose=1\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net._output_layer = net.initialize_layers()\n",
      "net_layers = net.get_all_layers()\n",
      "conv1_layer = net_layers[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv1_layer.get_output_shape()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "(None, 64, 44, 44)"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}